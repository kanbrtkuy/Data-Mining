# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sIFRf6o59HVW4Ur-v9vQVm4KaDH4NEOm
"""

import numpy as np


def data_fetch(file_path):
    with open(file_path, 'r') as file:
        data = [d.strip() for d in file]
    n = int(data[0])
    data_set = [[ch for ch in d.split()] for d in data[1:]]
    return n, data_set


def frequent_1itemsets(min_support, data_set):
    freq1 = {}
    for trans in data_set:
        for item in trans:
            freq1[item] = freq1.get(item, 0) + 1
    return {item: count for (item, count) in freq1.items() if count >= min_support}


def increment_itemset(frequent_kitemsets, new_len):
    frequent_increment = []
    length = len(frequent_kitemsets)
    for i in range(length):
        for j in range(i + 1, length):
            if (sorted(frequent_kitemsets[i][:new_len - 2]) == sorted(frequent_kitemsets[j][:new_len - 2])):
                temp = set(frequent_kitemsets[i]).union(frequent_kitemsets[j])
                frequent_increment.append(sorted(temp))
    return frequent_increment


def calc_support(frequent_kitemsets, min_support, data_set):
    freq_k = {}
    for trans in data_set:
        for items in frequent_kitemsets:
            if set(items).issubset(trans):
                key = ' '.join(items)
                freq_k[key] = freq_k.get(key, 0) + 1
    return {items: count for (items, count) in freq_k.items() if count >= min_support}


def write(frequent_dict, mode, output_path):
    sorted_list = sorted(frequent_dict.items(), key=lambda x: (-x[1], x[0]))
    with open(output_path, mode) as f:
        if mode == 'a':
            f.write('\n')
        for item in sorted_list:
            f.write(f"{item[1]}: {item[0]}\n")


def closed_patterns(frequent_dict):
    freq_set = list(frequent_dict.keys())
    closed = frequent_dict.copy()
    for key1 in freq_set:
        for key2 in freq_set:
            if (set(key2) > set(key1)) and (frequent_dict[key2] == frequent_dict[key1]):
                closed[key1] = 0
    return {key: value for key, value in closed.items() if value}


def max_patterns(frequent_dict, min_support):
    freq_set = list(frequent_dict.keys())
    closed = frequent_dict.copy()
    for key1 in freq_set:
        for key2 in freq_set:
            if (set(key2) > set(key1)) and (frequent_dict[key2] >= min_support):
                closed[key1] = 0
    return {key: value for key, value in closed.items() if value}


def freq_pattern_mining():
    file_path = 'test_input.txt'
    output_path = 'res.txt'
    min_support, data_set = data_fetch(file_path)

    f1 = frequent_1itemsets(min_support, data_set)
    frequent_dict = f1

    f1_list = [[x] for x in f1.keys()]
    frequent_kitemsets = increment_itemset(f1_list, 2)
    fk = calc_support(frequent_kitemsets, min_support, data_set)
    frequent_dict.update(fk)

    for len_k in range(3, len(f1.keys()) + 1):
        frequent_kitemsets = increment_itemset(frequent_kitemsets, len_k)
        fk = calc_support(frequent_kitemsets, min_support, data_set)
        if not fk:
            break
        frequent_dict.update(fk)

    write(frequent_dict, 'w', output_path)
    closed_patterns_dict = closed_patterns(frequent_dict)
    write(closed_patterns_dict, 'a', output_path)
    max_pattern = max_patterns(frequent_dict, min_support)
    write(max_pattern, 'a', output_path)


def main():
    freq_pattern_mining()


if __name__ == "__main__":
    main()